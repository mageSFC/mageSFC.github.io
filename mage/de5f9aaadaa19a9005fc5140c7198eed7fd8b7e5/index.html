<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Hadoopå­¦ä¹ ç¬”è®°æ€»ç»“ | é©¬å“¥ç§æˆ¿èœ</title><meta name="author" content="mage"><meta name="copyright" content="mage"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="å¼•è¨€Hadoopåˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿ(HDFS)è¢«è®¾è®¡æˆé€‚åˆè¿è¡Œåœ¨é€šç”¨ç¡¬ä»¶(commodity hardware)ä¸Šçš„åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿã€‚å®ƒå’Œç°æœ‰çš„åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿæœ‰å¾ˆå¤šå…±åŒç‚¹ã€‚ä½†åŒæ—¶ï¼Œå®ƒå’Œå…¶ä»–çš„åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿçš„åŒºåˆ«ä¹Ÿæ˜¯å¾ˆæ˜æ˜¾çš„ã€‚HDFSæ˜¯ä¸€ä¸ªé«˜åº¦å®¹é”™æ€§çš„ç³»ç»Ÿï¼Œé€‚åˆéƒ¨ç½²åœ¨å»‰ä»·çš„æœºå™¨ä¸Šã€‚HDFSèƒ½æä¾›é«˜ååé‡çš„æ•°æ®è®¿é—®ï¼Œéå¸¸é€‚åˆå¤§è§„æ¨¡æ•°æ®é›†ä¸Šçš„åº”ç”¨ã€‚HDFSæ”¾å®½äº†ä¸€éƒ¨åˆ†POSIXçº¦æŸï¼Œæ¥å®ç°æµå¼è¯»å–æ–‡ä»¶ç³»ç»Ÿæ•°æ®">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoopå­¦ä¹ ç¬”è®°æ€»ç»“">
<meta property="og:url" content="https://magesfc.github.io/mage/de5f9aaadaa19a9005fc5140c7198eed7fd8b7e5/">
<meta property="og:site_name" content="é©¬å“¥ç§æˆ¿èœ">
<meta property="og:description" content="å¼•è¨€Hadoopåˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿ(HDFS)è¢«è®¾è®¡æˆé€‚åˆè¿è¡Œåœ¨é€šç”¨ç¡¬ä»¶(commodity hardware)ä¸Šçš„åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿã€‚å®ƒå’Œç°æœ‰çš„åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿæœ‰å¾ˆå¤šå…±åŒç‚¹ã€‚ä½†åŒæ—¶ï¼Œå®ƒå’Œå…¶ä»–çš„åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿçš„åŒºåˆ«ä¹Ÿæ˜¯å¾ˆæ˜æ˜¾çš„ã€‚HDFSæ˜¯ä¸€ä¸ªé«˜åº¦å®¹é”™æ€§çš„ç³»ç»Ÿï¼Œé€‚åˆéƒ¨ç½²åœ¨å»‰ä»·çš„æœºå™¨ä¸Šã€‚HDFSèƒ½æä¾›é«˜ååé‡çš„æ•°æ®è®¿é—®ï¼Œéå¸¸é€‚åˆå¤§è§„æ¨¡æ•°æ®é›†ä¸Šçš„åº”ç”¨ã€‚HDFSæ”¾å®½äº†ä¸€éƒ¨åˆ†POSIXçº¦æŸï¼Œæ¥å®ç°æµå¼è¯»å–æ–‡ä»¶ç³»ç»Ÿæ•°æ®">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://t.mwm.moe/fj/">
<meta property="article:published_time" content="2022-02-23T09:47:19.000Z">
<meta property="article:modified_time" content="2022-02-23T09:47:19.000Z">
<meta property="article:author" content="mage">
<meta property="article:tag" content="hadoop">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://t.mwm.moe/fj/"><link rel="shortcut icon" href="https://www.zeekrlife.com/favicon.png"><link rel="canonical" href="https://magesfc.github.io/mage/de5f9aaadaa19a9005fc5140c7198eed7fd8b7e5/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":400},
  copy: {
    success: 'å¤åˆ¶æˆåŠŸ',
    error: 'å¤åˆ¶é”™è¯¯',
    noSupport: 'æµè§ˆå™¨ä¸æ”¯æŒ'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: 'å¤©',
  date_suffix: {
    just: 'åˆšåˆš',
    min: 'åˆ†é’Ÿå‰',
    hour: 'å°æ—¶å‰',
    day: 'å¤©å‰',
    month: 'ä¸ªæœˆå‰'
  },
  copyright: {"limitCount":150,"languages":{"author":"ä½œè€…: mage","link":"é“¾æ¥: ","source":"æ¥æº: é©¬å“¥ç§æˆ¿èœ","info":"è‘—ä½œæƒå½’ä½œè€…æ‰€æœ‰ã€‚å•†ä¸šè½¬è½½è¯·è”ç³»ä½œè€…è·å¾—æˆæƒï¼Œéå•†ä¸šè½¬è½½è¯·æ³¨æ˜å‡ºå¤„ã€‚"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Hadoopå­¦ä¹ ç¬”è®°æ€»ç»“',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-02-23 17:47:19'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><style type="text/css">.card-announcement .social-button{margin:.6rem 0 0 0;text-align:center}.card-announcement .social-button a{display:block;background-color:var(--btn-bg);color:var(--btn-color);text-align:center;line-height:2.4;margin:4px 0}.card-announcement .social-button a:hover{background-color:var(--btn-hover-color)}</style><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "/img/loading.gif" data-lazy-src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">æ–‡ç« </div><div class="length-num">213</div></a><a href="/tags/"><div class="headline">æ ‡ç­¾</div><div class="length-num">228</div></a><a href="/categories/"><div class="headline">åˆ†ç±»</div><div class="length-num">40</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> é¦–é¡µ</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-compass"></i><span> ç›®å½•</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> å½’æ¡£</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> æ ‡ç­¾</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> åˆ†ç±»</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-book"></i><span> ç²¾é€‰æ–‡æ¡£</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener" href="https://butterfly.js.org/posts/21cfbf15/"><span> ğŸš€ å¿«é€Ÿå¼€å§‹</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://butterfly.js.org/posts/dc584b87/"><span> ğŸ“‘ ä¸»é¢˜é¡µé¢</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://butterfly.js.org/posts/4aa8abbe/"><span> ğŸ›  ä¸»é¢˜é…ç½®-1</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://butterfly.js.org/posts/ceeb73f/"><span> ğŸ›  ä¸»é¢˜é…ç½®-2</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://butterfly.js.org/posts/98d20436/"><span> â“ ä¸»é¢˜é—®ç­”</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://butterfly.js.org/posts/4073eda/"><span> âš¡ï¸ è¿›é˜¶æ•™ç¨‹</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://butterfly.js.org/posts/198a4240/"><span> âœ¨ æ›´æ–°æ—¥å¿—</span></a></li></ul></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://butterfly.js.org/link/"><i class="fa-fw fas fa-thumbs-up"></i><span> å…¶ä»–ç¤ºä¾‹</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> å…³äº</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://t.mwm.moe/fj/')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">é©¬å“¥ç§æˆ¿èœ</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> é¦–é¡µ</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-compass"></i><span> ç›®å½•</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> å½’æ¡£</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> æ ‡ç­¾</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> åˆ†ç±»</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-book"></i><span> ç²¾é€‰æ–‡æ¡£</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener" href="https://butterfly.js.org/posts/21cfbf15/"><span> ğŸš€ å¿«é€Ÿå¼€å§‹</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://butterfly.js.org/posts/dc584b87/"><span> ğŸ“‘ ä¸»é¢˜é¡µé¢</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://butterfly.js.org/posts/4aa8abbe/"><span> ğŸ›  ä¸»é¢˜é…ç½®-1</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://butterfly.js.org/posts/ceeb73f/"><span> ğŸ›  ä¸»é¢˜é…ç½®-2</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://butterfly.js.org/posts/98d20436/"><span> â“ ä¸»é¢˜é—®ç­”</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://butterfly.js.org/posts/4073eda/"><span> âš¡ï¸ è¿›é˜¶æ•™ç¨‹</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://butterfly.js.org/posts/198a4240/"><span> âœ¨ æ›´æ–°æ—¥å¿—</span></a></li></ul></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://butterfly.js.org/link/"><i class="fa-fw fas fa-thumbs-up"></i><span> å…¶ä»–ç¤ºä¾‹</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> å…³äº</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Hadoopå­¦ä¹ ç¬”è®°æ€»ç»“</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">å‘è¡¨äº</span><time class="post-meta-date-created" datetime="2022-02-23T09:47:19.000Z" title="å‘è¡¨äº 2022-02-23 17:47:19">2022-02-23</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">æ›´æ–°äº</span><time class="post-meta-date-updated" datetime="2022-02-23T09:47:19.000Z" title="æ›´æ–°äº 2022-02-23 17:47:19">2022-02-23</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/hadoop/">hadoop</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Hadoopå­¦ä¹ ç¬”è®°æ€»ç»“"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">é˜…è¯»é‡:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="å¼•è¨€"><a href="#å¼•è¨€" class="headerlink" title="å¼•è¨€"></a>å¼•è¨€</h1><p>Hadoopåˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿ(HDFS)è¢«è®¾è®¡æˆé€‚åˆè¿è¡Œåœ¨é€šç”¨ç¡¬ä»¶(commodity hardware)ä¸Šçš„åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿã€‚<br>å®ƒå’Œç°æœ‰çš„åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿæœ‰å¾ˆå¤šå…±åŒç‚¹ã€‚ä½†åŒæ—¶ï¼Œå®ƒå’Œå…¶ä»–çš„åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿçš„åŒºåˆ«ä¹Ÿæ˜¯å¾ˆæ˜æ˜¾çš„ã€‚<br>HDFSæ˜¯ä¸€ä¸ªé«˜åº¦å®¹é”™æ€§çš„ç³»ç»Ÿï¼Œé€‚åˆéƒ¨ç½²åœ¨å»‰ä»·çš„æœºå™¨ä¸Šã€‚HDFSèƒ½æä¾›é«˜ååé‡çš„æ•°æ®è®¿é—®ï¼Œéå¸¸é€‚åˆå¤§è§„æ¨¡æ•°æ®é›†ä¸Šçš„åº”ç”¨ã€‚<br>HDFSæ”¾å®½äº†ä¸€éƒ¨åˆ†POSIXçº¦æŸï¼Œæ¥å®ç°æµå¼è¯»å–æ–‡ä»¶ç³»ç»Ÿæ•°æ®çš„ç›®çš„ã€‚HDFSåœ¨æœ€å¼€å§‹æ˜¯ä½œä¸ºApache Nutchæœç´¢å¼•æ“é¡¹ç›®çš„åŸºç¡€æ¶æ„è€Œå¼€å‘çš„ã€‚<br>HDFSæ˜¯Apache Hadoop Coreé¡¹ç›®çš„ä¸€éƒ¨åˆ†ã€‚è¿™ä¸ªé¡¹ç›®çš„åœ°å€æ˜¯<a target="_blank" rel="noopener" href="http://hadoop.apache.org/core/%E3%80%82">http://hadoop.apache.org/core/ã€‚</a></p>
<h1 id="Namenode-å’Œ-Datanode"><a href="#Namenode-å’Œ-Datanode" class="headerlink" title="Namenode å’Œ Datanode"></a>Namenode å’Œ Datanode</h1><p>HDFSé‡‡ç”¨master&#x2F;slaveæ¶æ„ã€‚ä¸€ä¸ªHDFSé›†ç¾¤æ˜¯ç”±ä¸€ä¸ªNamenodeå’Œä¸€å®šæ•°ç›®çš„Datanodesç»„æˆã€‚<br>Namenodeæ˜¯ä¸€ä¸ªä¸­å¿ƒæœåŠ¡å™¨ï¼Œè´Ÿè´£ç®¡ç†æ–‡ä»¶ç³»ç»Ÿçš„åå­—ç©ºé—´(namespace)ä»¥åŠå®¢æˆ·ç«¯å¯¹æ–‡ä»¶çš„è®¿é—®ã€‚<br>é›†ç¾¤ä¸­çš„Datanodeä¸€èˆ¬æ˜¯ä¸€ä¸ªèŠ‚ç‚¹ä¸€ä¸ªï¼Œè´Ÿè´£ç®¡ç†å®ƒæ‰€åœ¨èŠ‚ç‚¹ä¸Šçš„å­˜å‚¨ã€‚HDFSæš´éœ²äº†æ–‡ä»¶ç³»ç»Ÿçš„åå­—ç©ºé—´ï¼Œ<br>ç”¨æˆ·èƒ½å¤Ÿä»¥æ–‡ä»¶çš„å½¢å¼åœ¨ä¸Šé¢å­˜å‚¨æ•°æ®ã€‚ä»å†…éƒ¨çœ‹ï¼Œä¸€ä¸ªæ–‡ä»¶å…¶å®è¢«åˆ†æˆä¸€ä¸ªæˆ–å¤šä¸ªæ•°æ®å—ï¼Œè¿™äº›å—å­˜å‚¨åœ¨<br>ä¸€ç»„Datanodeä¸Šã€‚Namenodeæ‰§è¡Œæ–‡ä»¶ç³»ç»Ÿçš„åå­—ç©ºé—´æ“ä½œï¼Œæ¯”å¦‚æ‰“å¼€ã€å…³é—­ã€é‡å‘½åæ–‡ä»¶æˆ–ç›®å½•ã€‚å®ƒä¹Ÿè´Ÿè´£<br>ç¡®å®šæ•°æ®å—åˆ°å…·ä½“DatanodeèŠ‚ç‚¹çš„æ˜ å°„ã€‚Datanodeè´Ÿè´£å¤„ç†æ–‡ä»¶ç³»ç»Ÿå®¢æˆ·ç«¯çš„è¯»å†™è¯·æ±‚ã€‚åœ¨Namenodeçš„ç»Ÿä¸€<br>è°ƒåº¦ä¸‹è¿›è¡Œæ•°æ®å—çš„åˆ›å»ºã€åˆ é™¤å’Œå¤åˆ¶ã€‚</p>
<p>Namenodeå’ŒDatanodeè¢«è®¾è®¡æˆå¯ä»¥åœ¨æ™®é€šçš„å•†ç”¨æœºå™¨ä¸Šè¿è¡Œã€‚è¿™äº›æœºå™¨ä¸€èˆ¬è¿è¡Œç€GNU&#x2F;Linuxæ“ä½œç³»ç»Ÿ(OS)ã€‚<br>HDFSé‡‡ç”¨Javaè¯­è¨€å¼€å‘ï¼Œå› æ­¤ä»»ä½•æ”¯æŒJavaçš„æœºå™¨éƒ½å¯ä»¥éƒ¨ç½²Namenodeæˆ–Datanodeã€‚ç”±äºé‡‡ç”¨äº†å¯ç§»æ¤æ€§æ<br>å¼ºçš„Javaè¯­è¨€ï¼Œä½¿å¾—HDFSå¯ä»¥éƒ¨ç½²åˆ°å¤šç§ç±»å‹çš„æœºå™¨ä¸Šã€‚ä¸€ä¸ªå…¸å‹çš„éƒ¨ç½²åœºæ™¯æ˜¯ä¸€å°æœºå™¨ä¸Šåªè¿è¡Œä¸€ä¸ªNamenodeå®ä¾‹ï¼Œ<br>è€Œé›†ç¾¤ä¸­çš„å…¶å®ƒæœºå™¨åˆ†åˆ«è¿è¡Œä¸€ä¸ªDatanodeå®ä¾‹ã€‚è¿™ç§æ¶æ„å¹¶ä¸æ’æ–¥åœ¨ä¸€å°æœºå™¨ä¸Šè¿è¡Œå¤šä¸ªDatanodeï¼Œ<br>åªä¸è¿‡è¿™æ ·çš„æƒ…å†µæ¯”è¾ƒå°‘è§ã€‚</p>
<p>é›†ç¾¤ä¸­å•ä¸€Namenodeçš„ç»“æ„å¤§å¤§ç®€åŒ–äº†ç³»ç»Ÿçš„æ¶æ„ã€‚Namenodeæ˜¯æ‰€æœ‰HDFSå…ƒæ•°æ®çš„ä»²è£è€…å’Œç®¡ç†è€…ï¼Œ<br>è¿™æ ·ï¼Œç”¨æˆ·æ•°æ®æ°¸è¿œä¸ä¼šæµè¿‡Namenodeã€‚</p>
<p>Hadoopéƒ¨ç½²æ¨¡å¼æœ‰ï¼šæœ¬åœ°æ¨¡å¼ã€ä¼ªåˆ†å¸ƒæ¨¡å¼ã€å®Œå…¨åˆ†å¸ƒå¼æ¨¡å¼ã€HAå®Œå…¨åˆ†å¸ƒå¼æ¨¡å¼ã€‚</p>
<p>åŒºåˆ†çš„ä¾æ®æ˜¯NameNodeã€DataNodeã€ResourceManagerã€NodeManagerç­‰æ¨¡å—è¿è¡Œåœ¨å‡ ä¸ªJVMè¿›ç¨‹ã€å‡ ä¸ªæœºå™¨ã€‚</p>
<h1 id="å®‰è£…hadoopå‡†å¤‡"><a href="#å®‰è£…hadoopå‡†å¤‡" class="headerlink" title="å®‰è£…hadoopå‡†å¤‡"></a>å®‰è£…hadoopå‡†å¤‡</h1><p>1.åˆ›å»ºhadoopç³»ç»Ÿè´¦å·</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># è¿™é‡Œåˆ›å»ºä¸€ä¸ªæ™®é€šçš„linuxç³»ç»Ÿè´¦å·ï¼Œè®©hadoopè¿è¡Œåœ¨è¿™ä¸ªè´¦å·ä¸‹é¢ï¼Œä¸è¦ç›´æ¥è¿è¡Œåœ¨rootè´¦å·ä¸‹é¢</span></span><br><span class="line"><span class="comment"># è´¦å·çš„homeç›®å½•å¯ä»¥æ ¹æ®éœ€è¦æŒ‡å®šï¼Œè¿™é‡Œé»˜è®¤ä½¿ç”¨/home/hadoop</span></span><br><span class="line"></span><br><span class="line">sudo useradd -m -s /bin/bash hadoop</span><br><span class="line"></span><br><span class="line"><span class="comment"># ä¹Ÿä¸è¦è®¾ç½®å¯†ç ï¼Œåˆ‡æ¢å°±ç”¨ su æ¥åˆ‡æ¢</span></span><br><span class="line">sudo su - hadoop</span><br></pre></td></tr></table></figure>

<p>2.å®‰è£… JAVA</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">java -version</span><br><span class="line">openjdk version <span class="string">&quot;1.8.0_91&quot;</span></span><br><span class="line">OpenJDK Runtime Environment (build 1.8.0_91-b14)</span><br><span class="line">OpenJDK 64-Bit Server VM (build 25.91-b14, mixed mode)</span><br></pre></td></tr></table></figure>

<p>3.å®‰è£… SSH</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">è¿™ä¸ªåŸºæœ¬ä¸Šæ˜¯ç³»ç»Ÿéƒ½è‡ªå¸¦çš„æœ‰äº†</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>4.ç”Ÿæˆssh key</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -C <span class="string">&#x27;hadoop-master&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># é…ç½®å…å¯†ç çš„sshç™»å½•</span></span><br><span class="line"><span class="built_in">cat</span> .ssh/id_rsa.pub &gt;&gt; .ssh/authorized_keys</span><br><span class="line"></span><br><span class="line"><span class="built_in">chmod</span> 0600 .ssh/authorized_keys</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>5.ä¸‹è½½ hadoop-2.9.1.tar.gz</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># æœ‰ä¸ª345M å¤§å°</span></span><br><span class="line">http://mirrors.shu.edu.cn/apache/hadoop/common/hadoop-2.9.1/hadoop-2.9.1.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment">#è§£å‹</span></span><br><span class="line">tar xvzf hadoop-2.9.1.tar.gz</span><br><span class="line"></span><br><span class="line">[hadoop@localhost ~]$ <span class="built_in">ls</span></span><br><span class="line">hadoop-2.9.1  hadoop-2.9.1.tar.gz</span><br><span class="line"></span><br><span class="line">[hadoop@localhost ~]$ <span class="built_in">ls</span> hadoop-2.9.1</span><br><span class="line">bin  etc  include  lib  libexec  LICENSE.txt  NOTICE.txt  README.txt  sbin  share</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[hadoop@localhost ~]$ ll hadoop-2.9.1</span><br><span class="line">æ€»ç”¨é‡ 152</span><br><span class="line">drwxr-xr-x. 2 hadoop hadoop   4096 4æœˆ  16 2018 bin</span><br><span class="line">drwxr-xr-x. 3 hadoop hadoop   4096 4æœˆ  16 2018 etc</span><br><span class="line">drwxr-xr-x. 2 hadoop hadoop   4096 4æœˆ  16 2018 include</span><br><span class="line">drwxr-xr-x. 3 hadoop hadoop   4096 4æœˆ  16 2018 lib</span><br><span class="line">drwxr-xr-x. 2 hadoop hadoop   4096 4æœˆ  16 2018 libexec</span><br><span class="line">-rw-r--r--. 1 hadoop hadoop 106210 4æœˆ  16 2018 LICENSE.txt</span><br><span class="line">-rw-r--r--. 1 hadoop hadoop  15915 4æœˆ  16 2018 NOTICE.txt</span><br><span class="line">-rw-r--r--. 1 hadoop hadoop   1366 4æœˆ  16 2018 README.txt</span><br><span class="line">drwxr-xr-x. 3 hadoop hadoop   4096 4æœˆ  16 2018 sbin</span><br><span class="line">drwxr-xr-x. 4 hadoop hadoop   4096 4æœˆ  16 2018 share</span><br><span class="line"></span><br><span class="line"><span class="comment"># ä¸‹è½½åˆ°/home/hadoopå®¶ç›®å½•ä¸‹é¢å°±å¯ä»¥äº†ï¼Œè§£å‹ä¹Ÿæ”¾åˆ°è¿™ä¸ªç›®å½•ä¸‹é¢</span></span><br></pre></td></tr></table></figure>


<p>6.å¯åŠ¨hadoop</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">â”œâ”€java,28743 -Dproc_namenode -Xmx1000m -Djava.library.path=/home/hadoop/hadoop-2.9.1/lib -Djava.net.preferIPv4Stack=<span class="literal">true</span> -Dhadoop.log.dir=/home/hadoop/hadoop-2.9.1/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/home/hadoop/hadoop-2.9.1 -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=<span class="literal">true</span> -Djava.net.preferIPv4Stack=<span class="literal">true</span> -Djava.net.preferIPv4Stack=<span class="literal">true</span> -Dhadoop.log.dir=/home/hadoop/hadoop-2.9.1/logs -Dhadoop.log.file=hadoop-hadoop-namenode-localhost.localdomain.log -Dhadoop.home.dir=/home/hadoop/hadoop-2.9.1 -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=<span class="literal">true</span> -Dhadoop.security.logger=INFO,RFAS -Dhdfs.audit.logger=INFO,NullAppender -Dhadoop.security.logger=INFO,RFAS -Dhdfs.audit.logger=INFO,NullAppender -Dhadoop.security.logger=INFO,RFAS -Dhdfs.audit.logger=INFO,NullAppender -Dhadoop.security.logger=INFO,RFAS org.apache.hadoop.hdfs.server.namenode.NameNode</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">â”œâ”€java,28994 -Dproc_datanode -Xmx1000m -Djava.library.path=/home/hadoop/hadoop-2.9.1/lib -Djava.net.preferIPv4Stack=<span class="literal">true</span> -Dhadoop.log.dir=/home/hadoop/hadoop-2.9.1/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/home/hadoop/hadoop-2.9.1 -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=<span class="literal">true</span> -Djava.net.preferIPv4Stack=<span class="literal">true</span> -Djava.net.preferIPv4Stack=<span class="literal">true</span> -Dhadoop.log.dir=/home/hadoop/hadoop-2.9.1/logs -Dhadoop.log.file=hadoop-hadoop-datanode-localhost.localdomain.log -Dhadoop.home.dir=/home/hadoop/hadoop-2.9.1 -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=<span class="literal">true</span> -server -Dhadoop.security.logger=ERROR,RFAS -Dhadoop.security.logger=ERROR,RFAS -Dhadoop.security.logger=ERROR,RFAS -Dhadoop.security.logger=INFO,RFAS org.apache.hadoop.hdfs.server.datanode.DataNode</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">â”œâ”€java,29350 -Dproc_secondarynamenode -Xmx1000m -Djava.library.path=/home/hadoop/hadoop-2.9.1/lib -Djava.net.preferIPv4Stack=<span class="literal">true</span> -Dhadoop.log.dir=/home/hadoop/hadoop-2.9.1/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/home/hadoop/hadoop-2.9.1 -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=<span class="literal">true</span> -Djava.net.preferIPv4Stack=<span class="literal">true</span> -Djava.net.preferIPv4Stack=<span class="literal">true</span> -Dhadoop.log.dir=/home/hadoop/hadoop-2.9.1/logs -Dhadoop.log.file=hadoop-hadoop-secondarynamenode-localhost.localdomain.log -Dhadoop.home.dir=/home/hadoop/hadoop-2.9.1 -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=<span class="literal">true</span> -Dhadoop.security.logger=INFO,RFAS -Dhdfs.audit.logger=INFO,NullAppender -Dhadoop.security.logger=INFO,RFAS -Dhdfs.audit.logger=INFO,NullAppender -Dhadoop.security.logger=INFO,RFAS -Dhdfs.audit.logger=INFO,NullAppender -Dhadoop.security.logger=INFO,RFAS org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode</span><br><span class="line"></span><br><span class="line">â”œâ”€java,29606 -Dproc_resourcemanager -Xmx1000m -Dhadoop.log.dir=/home/hadoop/hadoop-2.9.1/logs -Dyarn.log.dir=/home/hadoop/hadoop-2.9.1/logs -Dhadoop.log.file=yarn-hadoop-resourcemanager-localhost.localdomain.log -Dyarn.log.file=yarn-hadoop-resourcemanager-localhost.localdomain.log -Dyarn.home.dir= -Dyarn.id.str=hadoop -Dhadoop.root.logger=INFO,RFA -Dyarn.root.logger=INFO,RFA -Dyarn.policy.file=hadoop-policy.xml -Dhadoop.log.dir=/home/hadoop/hadoop-2.9.1/logs -Dyarn.log.dir=/home/hadoop/hadoop-2.9.1/logs -Dhadoop.log.file=yarn-hadoop-resourcemanager-localhost.localdomain.log -Dyarn.log.file=yarn-hadoop-resourcemanager-localhost.localdomain.log -Dyarn.home.dir=/home/hadoop/hadoop-2.9.1 -Dhadoop.home.dir=/home/hadoop/hadoop-2.9.1 -Dhadoop.root.logger=INFO,RFA -Dyarn.root.logger=INFO,RFA -classpath /home/hadoop/hadoop-2.9.1/etc/hadoop:/home/hadoop/hadoop-2.9.1/etc/hadoop:/home/hadoop/hadoop-2.9.1/etc/hadoop:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/*:/home/hadoop/hadoop-2.9.1/share/hadoop/common/*:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/*:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/*:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/*:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/*:/home/hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/*:/home/hadoop/hadoop-2.9.1/share/hadoop/mapreduce/*:/home/hadoop/hadoop-2.9.1/contrib/capacity-scheduler/*.jar:/home/hadoop/hadoop-2.9.1/contrib/capacity-scheduler/*.jar:/home/hadoop/hadoop-2.9.1/contrib/capacity-scheduler/*.jar:/home/hadoop/hadoop-2.9.1/contrib/capacity-scheduler/*.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/*:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/*:/home/hadoop/hadoop-2.9.1/etc/hadoop/rm-config/log4j.properties:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/timelineservice/*:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/timelineservice/lib/* org.apache.hadoop.yarn.server.resourcemanager.ResourceManager</span><br><span class="line"></span><br><span class="line">â”œâ”€java,29930 -Dproc_nodemanager -Xmx1000m -Dhadoop.log.dir=/home/hadoop/hadoop-2.9.1/logs -Dyarn.log.dir=/home/hadoop/hadoop-2.9.1/logs -Dhadoop.log.file=yarn-hadoop-nodemanager-localhost.localdomain.log -Dyarn.log.file=yarn-hadoop-nodemanager-localhost.localdomain.log -Dyarn.home.dir= -Dyarn.id.str=hadoop -Dhadoop.root.logger=INFO,RFA -Dyarn.root.logger=INFO,RFA -Dyarn.policy.file=hadoop-policy.xml -server -Dhadoop.log.dir=/home/hadoop/hadoop-2.9.1/logs -Dyarn.log.dir=/home/hadoop/hadoop-2.9.1/logs -Dhadoop.log.file=yarn-hadoop-nodemanager-localhost.localdomain.log -Dyarn.log.file=yarn-hadoop-nodemanager-localhost.localdomain.log -Dyarn.home.dir=/home/hadoop/hadoop-2.9.1 -Dhadoop.home.dir=/home/hadoop/hadoop-2.9.1 -Dhadoop.root.logger=INFO,RFA -Dyarn.root.logger=INFO,RFA -classpath /home/hadoop/hadoop-2.9.1/etc/hadoop:/home/hadoop/hadoop-2.9.1/etc/hadoop:/home/hadoop/hadoop-2.9.1/etc/hadoop:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/*:/home/hadoop/hadoop-2.9.1/share/hadoop/common/*:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/*:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/*:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/*:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/*:/home/hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/*:/home/hadoop/hadoop-2.9.1/share/hadoop/mapreduce/*:/home/hadoop/hadoop-2.9.1/contrib/capacity-scheduler/*.jar:/home/hadoop/hadoop-2.9.1/contrib/capacity-scheduler/*.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/*:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/*:/home/hadoop/hadoop-2.9.1/etc/hadoop/nm-config/log4j.properties:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/timelineservice/*:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/timelineservice/lib/* org.apache.hadoop.yarn.server.nodemanager.NodeManager</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="æœ¬åœ°æ¨¡å¼éƒ¨ç½²"><a href="#æœ¬åœ°æ¨¡å¼éƒ¨ç½²" class="headerlink" title="æœ¬åœ°æ¨¡å¼éƒ¨ç½²"></a>æœ¬åœ°æ¨¡å¼éƒ¨ç½²</h1><p>æœ¬åœ°æ¨¡å¼æ˜¯æœ€ç®€å•çš„æ¨¡å¼ï¼Œæ‰€æœ‰æ¨¡å—éƒ½è¿è¡Œä¸ä¸€ä¸ªJVMè¿›ç¨‹ä¸­ï¼Œä½¿ç”¨çš„æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿï¼Œè€Œä¸æ˜¯HDFSï¼Œæœ¬åœ°æ¨¡å¼ä¸»è¦æ˜¯ç”¨äºæœ¬åœ°å¼€å‘è¿‡ç¨‹ä¸­çš„è¿è¡Œè°ƒè¯•ç”¨ã€‚ä¸‹è½½hadoopå®‰è£…åŒ…åä¸ç”¨ä»»ä½•è®¾ç½®ï¼Œé»˜è®¤çš„å°±æ˜¯æœ¬åœ°æ¨¡å¼ã€‚</p>
<p>è¿è¡ŒMapReduceç¨‹åºï¼ŒéªŒè¯</p>
<p>1ã€ å‡†å¤‡mapreduceè¾“å…¥æ–‡ä»¶wc.input</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">$ <span class="built_in">cat</span> <span class="variable">$HOME</span>/wc.input</span><br><span class="line">hadoop mapreduce hive</span><br><span class="line">hbase spark storm</span><br><span class="line">sqoop hadoop hive</span><br><span class="line">spark hadoop</span><br></pre></td></tr></table></figure>

<p>2ã€ è¿è¡Œhadoopè‡ªå¸¦çš„mapreduce Demo</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@localhost ~]$ hadoop jar <span class="variable">$HADOOP_HOME</span>/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.1.jar wordcount wc.input output2</span><br><span class="line">18/10/22 12:39:26 WARN util.NativeCodeLoader: Unable to load native-hadoop library <span class="keyword">for</span> your platform... using builtin-java classes <span class="built_in">where</span> applicable</span><br><span class="line">18/10/22 12:39:26 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id</span><br><span class="line">18/10/22 12:39:26 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=</span><br><span class="line">18/10/22 12:39:26 INFO input.FileInputFormat: Total input files to process : 1</span><br><span class="line">18/10/22 12:39:26 INFO mapreduce.JobSubmitter: number of splits:1</span><br><span class="line">18/10/22 12:39:27 INFO mapreduce.JobSubmitter: Submitting tokens <span class="keyword">for</span> job: job_local841462251_0001</span><br><span class="line">18/10/22 12:39:27 INFO mapreduce.Job: The url to track the job: http://localhost:8080/</span><br><span class="line">18/10/22 12:39:27 INFO mapreduce.Job: Running job: job_local841462251_0001</span><br><span class="line">18/10/22 12:39:27 INFO mapred.LocalJobRunner: OutputCommitter <span class="built_in">set</span> <span class="keyword">in</span> config null</span><br><span class="line">18/10/22 12:39:27 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1</span><br><span class="line">18/10/22 12:39:27 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:<span class="literal">false</span>, ignore cleanup failures: <span class="literal">false</span></span><br><span class="line">18/10/22 12:39:27 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter</span><br><span class="line">18/10/22 12:39:27 INFO mapred.LocalJobRunner: Waiting <span class="keyword">for</span> map tasks</span><br><span class="line">18/10/22 12:39:27 INFO mapred.LocalJobRunner: Starting task: attempt_local841462251_0001_m_000000_0</span><br><span class="line">18/10/22 12:39:27 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1</span><br><span class="line">18/10/22 12:39:27 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:<span class="literal">false</span>, ignore cleanup failures: <span class="literal">false</span></span><br><span class="line">18/10/22 12:39:27 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]</span><br><span class="line">18/10/22 12:39:27 INFO mapred.MapTask: Processing <span class="built_in">split</span>: file:/home/hadoop/wc.input:0+71</span><br><span class="line">18/10/22 12:39:27 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)</span><br><span class="line">18/10/22 12:39:27 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100</span><br><span class="line">18/10/22 12:39:27 INFO mapred.MapTask: soft <span class="built_in">limit</span> at 83886080</span><br><span class="line">18/10/22 12:39:27 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600</span><br><span class="line">18/10/22 12:39:27 INFO mapred.MapTask: kvstart = 26214396; length = 6553600</span><br><span class="line">18/10/22 12:39:27 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask<span class="variable">$MapOutputBuffer</span></span><br><span class="line">18/10/22 12:39:27 INFO mapred.LocalJobRunner: </span><br><span class="line">18/10/22 12:39:27 INFO mapred.MapTask: Starting flush of map output</span><br><span class="line">18/10/22 12:39:27 INFO mapred.MapTask: Spilling map output</span><br><span class="line">18/10/22 12:39:27 INFO mapred.MapTask: bufstart = 0; bufend = 115; bufvoid = 104857600</span><br><span class="line">18/10/22 12:39:27 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214356(104857424); length = 41/6553600</span><br><span class="line">18/10/22 12:39:27 INFO mapred.MapTask: Finished spill 0</span><br><span class="line">18/10/22 12:39:27 INFO mapred.Task: Task:attempt_local841462251_0001_m_000000_0 is <span class="keyword">done</span>. And is <span class="keyword">in</span> the process of committing</span><br><span class="line">18/10/22 12:39:27 INFO mapred.LocalJobRunner: map</span><br><span class="line">18/10/22 12:39:27 INFO mapred.Task: Task <span class="string">&#x27;attempt_local841462251_0001_m_000000_0&#x27;</span> <span class="keyword">done</span>.</span><br><span class="line">18/10/22 12:39:27 INFO mapred.LocalJobRunner: Finishing task: attempt_local841462251_0001_m_000000_0</span><br><span class="line">18/10/22 12:39:27 INFO mapred.LocalJobRunner: map task executor complete.</span><br><span class="line">18/10/22 12:39:27 INFO mapred.LocalJobRunner: Waiting <span class="keyword">for</span> reduce tasks</span><br><span class="line">18/10/22 12:39:27 INFO mapred.LocalJobRunner: Starting task: attempt_local841462251_0001_r_000000_0</span><br><span class="line">18/10/22 12:39:27 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1</span><br><span class="line">18/10/22 12:39:27 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:<span class="literal">false</span>, ignore cleanup failures: <span class="literal">false</span></span><br><span class="line">18/10/22 12:39:27 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]</span><br><span class="line">18/10/22 12:39:27 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@65deffe9</span><br><span class="line">18/10/22 12:39:27 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10</span><br><span class="line">18/10/22 12:39:27 INFO reduce.EventFetcher: attempt_local841462251_0001_r_000000_0 Thread started: EventFetcher <span class="keyword">for</span> fetching Map Completion Events</span><br><span class="line">18/10/22 12:39:27 INFO reduce.LocalFetcher: localfetcher<span class="comment">#1 about to shuffle output of map attempt_local841462251_0001_m_000000_0 decomp: 90 len: 94 to MEMORY</span></span><br><span class="line">18/10/22 12:39:27 INFO reduce.InMemoryMapOutput: Read 90 bytes from map-output <span class="keyword">for</span> attempt_local841462251_0001_m_000000_0</span><br><span class="line">18/10/22 12:39:27 INFO reduce.MergeManagerImpl: closeInMemoryFile -&gt; map-output of size: 90, inMemoryMapOutputs.size() -&gt; 1, commitMemory -&gt; 0, usedMemory -&gt;90</span><br><span class="line">18/10/22 12:39:27 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning</span><br><span class="line">18/10/22 12:39:27 INFO mapred.LocalJobRunner: 1 / 1 copied.</span><br><span class="line">18/10/22 12:39:27 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs</span><br><span class="line">18/10/22 12:39:27 INFO mapred.Merger: Merging 1 sorted segments</span><br><span class="line">18/10/22 12:39:27 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 81 bytes</span><br><span class="line">18/10/22 12:39:27 INFO reduce.MergeManagerImpl: Merged 1 segments, 90 bytes to disk to satisfy reduce memory <span class="built_in">limit</span></span><br><span class="line">18/10/22 12:39:27 INFO reduce.MergeManagerImpl: Merging 1 files, 94 bytes from disk</span><br><span class="line">18/10/22 12:39:27 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce</span><br><span class="line">18/10/22 12:39:27 INFO mapred.Merger: Merging 1 sorted segments</span><br><span class="line">18/10/22 12:39:27 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 81 bytes</span><br><span class="line">18/10/22 12:39:27 INFO mapred.LocalJobRunner: 1 / 1 copied.</span><br><span class="line">18/10/22 12:39:27 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords</span><br><span class="line">18/10/22 12:39:27 INFO mapred.Task: Task:attempt_local841462251_0001_r_000000_0 is <span class="keyword">done</span>. And is <span class="keyword">in</span> the process of committing</span><br><span class="line">18/10/22 12:39:27 INFO mapred.LocalJobRunner: 1 / 1 copied.</span><br><span class="line">18/10/22 12:39:27 INFO mapred.Task: Task attempt_local841462251_0001_r_000000_0 is allowed to commit now</span><br><span class="line">18/10/22 12:39:27 INFO output.FileOutputCommitter: Saved output of task <span class="string">&#x27;attempt_local841462251_0001_r_000000_0&#x27;</span> to file:/home/hadoop/output2/_temporary/0/task_local841462251_0001_r_000000</span><br><span class="line">18/10/22 12:39:27 INFO mapred.LocalJobRunner: reduce &gt; reduce</span><br><span class="line">18/10/22 12:39:27 INFO mapred.Task: Task <span class="string">&#x27;attempt_local841462251_0001_r_000000_0&#x27;</span> <span class="keyword">done</span>.</span><br><span class="line">18/10/22 12:39:27 INFO mapred.LocalJobRunner: Finishing task: attempt_local841462251_0001_r_000000_0</span><br><span class="line">18/10/22 12:39:27 INFO mapred.LocalJobRunner: reduce task executor complete.</span><br><span class="line">18/10/22 12:39:28 INFO mapreduce.Job: Job job_local841462251_0001 running <span class="keyword">in</span> uber mode : <span class="literal">false</span></span><br><span class="line">18/10/22 12:39:28 INFO mapreduce.Job:  map 100% reduce 100%</span><br><span class="line">18/10/22 12:39:28 INFO mapreduce.Job: Job job_local841462251_0001 completed successfully</span><br><span class="line">18/10/22 12:39:28 INFO mapreduce.Job: Counters: 30</span><br><span class="line">	File System Counters</span><br><span class="line">		FILE: Number of bytes <span class="built_in">read</span>=607284</span><br><span class="line">		FILE: Number of bytes written=1537636</span><br><span class="line">		FILE: Number of <span class="built_in">read</span> operations=0</span><br><span class="line">		FILE: Number of large <span class="built_in">read</span> operations=0</span><br><span class="line">		FILE: Number of write operations=0</span><br><span class="line">	Map-Reduce Framework</span><br><span class="line">		Map input records=4</span><br><span class="line">		Map output records=11</span><br><span class="line">		Map output bytes=115</span><br><span class="line">		Map output materialized bytes=94</span><br><span class="line">		Input <span class="built_in">split</span> bytes=91</span><br><span class="line">		Combine input records=11</span><br><span class="line">		Combine output records=7</span><br><span class="line">		Reduce input <span class="built_in">groups</span>=7</span><br><span class="line">		Reduce shuffle bytes=94</span><br><span class="line">		Reduce input records=7</span><br><span class="line">		Reduce output records=7</span><br><span class="line">		Spilled Records=14</span><br><span class="line">		Shuffled Maps =1</span><br><span class="line">		Failed Shuffles=0</span><br><span class="line">		Merged Map outputs=1</span><br><span class="line">		GC time elapsed (ms)=0</span><br><span class="line">		Total committed heap usage (bytes)=525336576</span><br><span class="line">	Shuffle Errors</span><br><span class="line">		BAD_ID=0</span><br><span class="line">		CONNECTION=0</span><br><span class="line">		IO_ERROR=0</span><br><span class="line">		WRONG_LENGTH=0</span><br><span class="line">		WRONG_MAP=0</span><br><span class="line">		WRONG_REDUCE=0</span><br><span class="line">	File Input Format Counters </span><br><span class="line">		Bytes Read=71</span><br><span class="line">	File Output Format Counters </span><br><span class="line">		Bytes Written=72</span><br><span class="line">[hadoop@localhost ~]$ </span><br><span class="line"></span><br><span class="line">è¿™é‡Œå¯ä»¥çœ‹åˆ°job IDä¸­æœ‰<span class="built_in">local</span>å­—æ ·ï¼Œè¯´æ˜æ˜¯è¿è¡Œåœ¨æœ¬åœ°æ¨¡å¼ä¸‹çš„ã€‚</span><br></pre></td></tr></table></figure>

<p>3ã€ æŸ¥çœ‹è¾“å‡ºæ–‡ä»¶</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[hadoop@localhost ~]$ <span class="built_in">ls</span> -alh output2/</span><br><span class="line">æ€»ç”¨é‡ 20K</span><br><span class="line">drwxrwxr-x. 2 hadoop hadoop 4.0K 10æœˆ 22 12:39 .</span><br><span class="line">drwx------. 8 hadoop hadoop 4.0K 10æœˆ 22 12:39 ..</span><br><span class="line">-rw-r--r--. 1 hadoop hadoop   60 10æœˆ 22 12:39 part-r-00000</span><br><span class="line">-rw-r--r--. 1 hadoop hadoop   12 10æœˆ 22 12:39 .part-r-00000.crc</span><br><span class="line">-rw-r--r--. 1 hadoop hadoop    0 10æœˆ 22 12:39 _SUCCESS</span><br><span class="line">-rw-r--r--. 1 hadoop hadoop    8 10æœˆ 22 12:39 ._SUCCESS.crc</span><br><span class="line"></span><br><span class="line"><span class="comment"># è¾“å‡ºç›®å½•ä¸­æœ‰_SUCCESSæ–‡ä»¶è¯´æ˜JOBè¿è¡ŒæˆåŠŸï¼Œpart-r-00000æ˜¯è¾“å‡ºç»“æœæ–‡ä»¶ã€‚ </span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="Hadoopä¼ªåˆ†å¸ƒå¼æ¨¡å¼å®‰è£…"><a href="#Hadoopä¼ªåˆ†å¸ƒå¼æ¨¡å¼å®‰è£…" class="headerlink" title="Hadoopä¼ªåˆ†å¸ƒå¼æ¨¡å¼å®‰è£…"></a>Hadoopä¼ªåˆ†å¸ƒå¼æ¨¡å¼å®‰è£…</h1><p>1ã€ é…ç½®Hadoopç¯å¢ƒå˜é‡</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.91-2.b14.fc22.x86_64/jre</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/home/hadoop/hadoop-2.9.1</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/bin</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/sbin</span><br></pre></td></tr></table></figure>

<p>2ã€ é…ç½® hadoop-env.shã€mapred-env.shã€yarn-env.shæ–‡ä»¶çš„JAVA_HOMEå‚æ•°</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>3ã€ é…ç½®core-site.xml</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$&#123;HADOOP_HOME&#125;</span>/etc/hadoop/core-site.xml</span><br><span class="line">ï¼ˆ1ï¼‰ fs.defaultFSå‚æ•°é…ç½®çš„æ˜¯HDFSçš„åœ°å€ã€‚</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hdfs://10.0.63.48:8020&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    </span><br><span class="line">ï¼ˆ2ï¼‰ hadoop.tmp.diré…ç½®çš„æ˜¯Hadoopä¸´æ—¶ç›®å½•</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;/home/hadoop/hadoop-2.9.1/tmp&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">é»˜è®¤çš„hadoop.tmp.diræ˜¯/tmp/hadoop-<span class="variable">$&#123;user.name&#125;</span>,æ­¤æ—¶æœ‰ä¸ªé—®é¢˜å°±æ˜¯NameNodeä¼šå°†HDFSçš„å…ƒæ•°æ®å­˜å‚¨åœ¨è¿™ä¸ª/tmpç›®å½•ä¸‹ï¼Œ</span><br><span class="line">å¦‚æœæ“ä½œç³»ç»Ÿé‡å¯äº†ï¼Œç³»ç»Ÿä¼šæ¸…ç©º/tmpç›®å½•ä¸‹çš„ä¸œè¥¿ï¼Œå¯¼è‡´NameNodeå…ƒæ•°æ®ä¸¢å¤±ï¼Œæ˜¯ä¸ªéå¸¸ä¸¥é‡çš„é—®é¢˜ï¼Œæ‰€æœ‰æˆ‘ä»¬åº”è¯¥ä¿®æ”¹è¿™ä¸ªè·¯å¾„ã€‚</span><br></pre></td></tr></table></figure>

<p>4ã€ é…ç½®hdfs-site.xml</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">dfs.replicationé…ç½®çš„æ˜¯HDFSå­˜å‚¨æ—¶çš„å¤‡ä»½æ•°é‡ï¼Œå› ä¸ºè¿™é‡Œæ˜¯ä¼ªåˆ†å¸ƒå¼ç¯å¢ƒåªæœ‰ä¸€ä¸ªèŠ‚ç‚¹ï¼Œæ‰€ä»¥è¿™é‡Œè®¾ç½®ä¸º1ã€‚</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>5ã€ æ ¼å¼åŒ–HDFS </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@localhost hadoop-2.9.1]$ hdfs</span><br><span class="line">Usage: hdfs [--config confdir] [--loglevel loglevel] COMMAND</span><br><span class="line">       <span class="built_in">where</span> COMMAND is one of:</span><br><span class="line">  dfs                  run a filesystem <span class="built_in">command</span> on the file systems supported <span class="keyword">in</span> Hadoop.</span><br><span class="line">  classpath            prints the classpath</span><br><span class="line">  namenode -format     format the DFS filesystem</span><br><span class="line">  secondarynamenode    run the DFS secondary namenode</span><br><span class="line">  namenode             run the DFS namenode</span><br><span class="line">  journalnode          run the DFS journalnode</span><br><span class="line">  zkfc                 run the ZK Failover Controller daemon</span><br><span class="line">  datanode             run a DFS datanode</span><br><span class="line">  debug                run a Debug Admin to execute HDFS debug commands</span><br><span class="line">  dfsadmin             run a DFS admin client</span><br><span class="line">  dfsrouter            run the DFS router</span><br><span class="line">  dfsrouteradmin       manage Router-based federation</span><br><span class="line">  haadmin              run a DFS HA admin client</span><br><span class="line">  fsck                 run a DFS filesystem checking utility</span><br><span class="line">  balancer             run a cluster balancing utility</span><br><span class="line">  jmxget               get JMX exported values from NameNode or DataNode.</span><br><span class="line">  mover                run a utility to move block replicas across</span><br><span class="line">                       storage types</span><br><span class="line">  oiv                  apply the offline fsimage viewer to an fsimage</span><br><span class="line">  oiv_legacy           apply the offline fsimage viewer to an legacy fsimage</span><br><span class="line">  oev                  apply the offline edits viewer to an edits file</span><br><span class="line">  fetchdt              fetch a delegation token from the NameNode</span><br><span class="line">  getconf              get config values from configuration</span><br><span class="line">  <span class="built_in">groups</span>               get the <span class="built_in">groups</span> <span class="built_in">which</span> <span class="built_in">users</span> belong to</span><br><span class="line">  snapshotDiff         diff two snapshots of a directory or diff the</span><br><span class="line">                       current directory contents with a snapshot</span><br><span class="line">  lsSnapshottableDir   list all snapshottable <span class="built_in">dirs</span> owned by the current user</span><br><span class="line">						Use -<span class="built_in">help</span> to see options</span><br><span class="line">  portmap              run a portmap service</span><br><span class="line">  nfs3                 run an NFS version 3 gateway</span><br><span class="line">  cacheadmin           configure the HDFS cache</span><br><span class="line">  crypto               configure HDFS encryption zones</span><br><span class="line">  storagepolicies      list/get/set block storage policies</span><br><span class="line">  version              <span class="built_in">print</span> the version</span><br><span class="line"></span><br><span class="line">Most commands <span class="built_in">print</span> <span class="built_in">help</span> when invoked w/o parameters.</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[hadoop@localhost hadoop-2.9.1]$ hdfs namenode -format</span><br><span class="line">18/10/22 13:40:46 INFO namenode.NameNode: STARTUP_MSG: </span><br><span class="line">/************************************************************</span><br><span class="line">STARTUP_MSG: Starting NameNode</span><br><span class="line">STARTUP_MSG:   host = localhost.localdomain/127.0.0.1</span><br><span class="line">STARTUP_MSG:   args = [-format]</span><br><span class="line">STARTUP_MSG:   version = 2.9.1</span><br><span class="line">STARTUP_MSG:   classpath = *.jar</span><br><span class="line">STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e30710aea4e6e55e69372929106cf119af06fd0e; compiled by <span class="string">&#x27;root&#x27;</span> on 2018-04-16T09:33Z</span><br><span class="line">STARTUP_MSG:   java = 1.8.0_91</span><br><span class="line">************************************************************/</span><br><span class="line">18/10/22 13:40:46 INFO namenode.NameNode: registered UNIX signal handlers <span class="keyword">for</span> [TERM, HUP, INT]</span><br><span class="line">18/10/22 13:40:46 INFO namenode.NameNode: createNameNode [-format]</span><br><span class="line">18/10/22 13:40:46 WARN util.NativeCodeLoader: Unable to load native-hadoop library <span class="keyword">for</span> your platform... using builtin-java classes <span class="built_in">where</span> applicable</span><br><span class="line">Formatting using clusterid: CID-85451f7e-c811-4028-8eee-62d3202c00bc</span><br><span class="line">18/10/22 13:40:47 INFO namenode.FSEditLog: Edit logging is async:<span class="literal">true</span></span><br><span class="line">18/10/22 13:40:47 INFO namenode.FSNamesystem: KeyProvider: null</span><br><span class="line">18/10/22 13:40:47 INFO namenode.FSNamesystem: fsLock is fair: <span class="literal">true</span></span><br><span class="line">18/10/22 13:40:47 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: <span class="literal">false</span></span><br><span class="line">18/10/22 13:40:47 INFO namenode.FSNamesystem: fsOwner             = hadoop (auth:SIMPLE)</span><br><span class="line">18/10/22 13:40:47 INFO namenode.FSNamesystem: supergroup          = supergroup</span><br><span class="line">18/10/22 13:40:47 INFO namenode.FSNamesystem: isPermissionEnabled = <span class="literal">true</span></span><br><span class="line">18/10/22 13:40:47 INFO namenode.FSNamesystem: HA Enabled: <span class="literal">false</span></span><br><span class="line">18/10/22 13:40:47 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage <span class="built_in">set</span> to 0. Disabling file IO profiling</span><br><span class="line">18/10/22 13:40:47 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000</span><br><span class="line">18/10/22 13:40:47 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=<span class="literal">true</span></span><br><span class="line">18/10/22 13:40:47 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is <span class="built_in">set</span> to 000:00:00:00.000</span><br><span class="line">18/10/22 13:40:47 INFO blockmanagement.BlockManager: The block deletion will start around 2018 åæœˆ 22 13:40:47</span><br><span class="line">18/10/22 13:40:47 INFO util.GSet: Computing capacity <span class="keyword">for</span> map BlocksMap</span><br><span class="line">18/10/22 13:40:47 INFO util.GSet: VM <span class="built_in">type</span>       = 64-bit</span><br><span class="line">18/10/22 13:40:47 INFO util.GSet: 2.0% max memory 889 MB = 17.8 MB</span><br><span class="line">18/10/22 13:40:47 INFO util.GSet: capacity      = 2^21 = 2097152 entries</span><br><span class="line">18/10/22 13:40:47 INFO blockmanagement.BlockManager: dfs.block.access.token.enable=<span class="literal">false</span></span><br><span class="line">18/10/22 13:40:47 WARN conf.Configuration: No unit <span class="keyword">for</span> dfs.heartbeat.interval(3) assuming SECONDS</span><br><span class="line">18/10/22 13:40:47 WARN conf.Configuration: No unit <span class="keyword">for</span> dfs.namenode.safemode.extension(30000) assuming MILLISECONDS</span><br><span class="line">18/10/22 13:40:47 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033</span><br><span class="line">18/10/22 13:40:47 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0</span><br><span class="line">18/10/22 13:40:47 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000</span><br><span class="line">18/10/22 13:40:47 INFO blockmanagement.BlockManager: defaultReplication         = 1</span><br><span class="line">18/10/22 13:40:47 INFO blockmanagement.BlockManager: maxReplication             = 512</span><br><span class="line">18/10/22 13:40:47 INFO blockmanagement.BlockManager: minReplication             = 1</span><br><span class="line">18/10/22 13:40:47 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2</span><br><span class="line">18/10/22 13:40:47 INFO blockmanagement.BlockManager: replicationRecheckInterval = 3000</span><br><span class="line">18/10/22 13:40:47 INFO blockmanagement.BlockManager: encryptDataTransfer        = <span class="literal">false</span></span><br><span class="line">18/10/22 13:40:47 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000</span><br><span class="line">18/10/22 13:40:47 INFO namenode.FSNamesystem: Append Enabled: <span class="literal">true</span></span><br><span class="line">18/10/22 13:40:47 INFO util.GSet: Computing capacity <span class="keyword">for</span> map INodeMap</span><br><span class="line">18/10/22 13:40:47 INFO util.GSet: VM <span class="built_in">type</span>       = 64-bit</span><br><span class="line">18/10/22 13:40:47 INFO util.GSet: 1.0% max memory 889 MB = 8.9 MB</span><br><span class="line">18/10/22 13:40:47 INFO util.GSet: capacity      = 2^20 = 1048576 entries</span><br><span class="line">18/10/22 13:40:47 INFO namenode.FSDirectory: ACLs enabled? <span class="literal">false</span></span><br><span class="line">18/10/22 13:40:47 INFO namenode.FSDirectory: XAttrs enabled? <span class="literal">true</span></span><br><span class="line">18/10/22 13:40:47 INFO namenode.NameNode: Caching file names occurring more than 10 <span class="built_in">times</span></span><br><span class="line">18/10/22 13:40:47 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: falseskipCaptureAccessTimeOnlyChange: <span class="literal">false</span></span><br><span class="line">18/10/22 13:40:47 INFO util.GSet: Computing capacity <span class="keyword">for</span> map cachedBlocks</span><br><span class="line">18/10/22 13:40:47 INFO util.GSet: VM <span class="built_in">type</span>       = 64-bit</span><br><span class="line">18/10/22 13:40:47 INFO util.GSet: 0.25% max memory 889 MB = 2.2 MB</span><br><span class="line">18/10/22 13:40:47 INFO util.GSet: capacity      = 2^18 = 262144 entries</span><br><span class="line">18/10/22 13:40:47 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10</span><br><span class="line">18/10/22 13:40:47 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10</span><br><span class="line">18/10/22 13:40:47 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25</span><br><span class="line">18/10/22 13:40:47 INFO namenode.FSNamesystem: Retry cache on namenode is enabled</span><br><span class="line">18/10/22 13:40:47 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis</span><br><span class="line">18/10/22 13:40:47 INFO util.GSet: Computing capacity <span class="keyword">for</span> map NameNodeRetryCache</span><br><span class="line">18/10/22 13:40:47 INFO util.GSet: VM <span class="built_in">type</span>       = 64-bit</span><br><span class="line">18/10/22 13:40:47 INFO util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB</span><br><span class="line">18/10/22 13:40:47 INFO util.GSet: capacity      = 2^15 = 32768 entries</span><br><span class="line">18/10/22 13:40:47 INFO namenode.FSImage: Allocated new BlockPoolId: BP-648750324-127.0.0.1-1540186847111</span><br><span class="line">18/10/22 13:40:47 INFO common.Storage: Storage directory /home/hadoop/hadoop-2.9.1/tmp/dfs/name has been successfully formatted.</span><br><span class="line">18/10/22 13:40:47 INFO namenode.FSImageFormatProtobuf: Saving image file /home/hadoop/hadoop-2.9.1/tmp/dfs/name/current/fsimage.ckpt_0000000000000000000 using no compression</span><br><span class="line">18/10/22 13:40:47 INFO namenode.FSImageFormatProtobuf: Image file /home/hadoop/hadoop-2.9.1/tmp/dfs/name/current/fsimage.ckpt_0000000000000000000 of size 323 bytes saved <span class="keyword">in</span> 0 seconds .</span><br><span class="line">18/10/22 13:40:47 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid &gt;= 0</span><br><span class="line">18/10/22 13:40:47 INFO namenode.NameNode: SHUTDOWN_MSG: </span><br><span class="line">/************************************************************</span><br><span class="line">SHUTDOWN_MSG: Shutting down NameNode at localhost.localdomain/127.0.0.1</span><br><span class="line">************************************************************/</span><br><span class="line">[hadoop@localhost hadoop-2.9.1]$ </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[hadoop@localhost hadoop-2.9.1]$ tree tmp/</span><br><span class="line">tmp/</span><br><span class="line">â””â”€â”€ dfs</span><br><span class="line">    â””â”€â”€ name</span><br><span class="line">        â””â”€â”€ current</span><br><span class="line">            â”œâ”€â”€ fsimage_0000000000000000000</span><br><span class="line">            â”œâ”€â”€ fsimage_0000000000000000000.md5</span><br><span class="line">            â”œâ”€â”€ seen_txid</span><br><span class="line">            â””â”€â”€ VERSION</span><br><span class="line"></span><br><span class="line">3 directories, 4 files</span><br><span class="line">[hadoop@localhost hadoop-2.9.1]$ </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>fsimageæ˜¯NameNodeå…ƒæ•°æ®åœ¨å†…å­˜æ»¡äº†åï¼ŒæŒä¹…åŒ–ä¿å­˜åˆ°çš„æ–‡ä»¶ã€‚</p>
<p>fsimage*.md5 æ˜¯æ ¡éªŒæ–‡ä»¶ï¼Œç”¨äºæ ¡éªŒfsimageçš„å®Œæ•´æ€§ã€‚</p>
<p>seen_txid æ˜¯hadoopçš„ç‰ˆæœ¬</p>
<p>vessionæ–‡ä»¶é‡Œä¿å­˜ï¼š</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@localhost hadoop-2.9.1]$ <span class="built_in">cat</span> tmp/dfs/name/current/VERSION </span><br><span class="line"><span class="comment">#Mon Oct 22 13:40:47 CST 2018</span></span><br><span class="line">namespaceID=1544637935</span><br><span class="line">clusterID=CID-85451f7e-c811-4028-8eee-62d3202c00bc</span><br><span class="line">cTime=1540186847111</span><br><span class="line">storageType=NAME_NODE</span><br><span class="line">blockpoolID=BP-648750324-127.0.0.1-1540186847111</span><br><span class="line">layoutVersion=-63</span><br></pre></td></tr></table></figure>
<p>6ã€ å¯åŠ¨NameNode</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@localhost hadoop-2.9.1]$ hadoop-daemon.sh start namenode</span><br><span class="line">starting namenode, logging to /home/hadoop/hadoop-2.9.1/logs/hadoop-hadoop-namenode-localhost.localdomain.out</span><br></pre></td></tr></table></figure>
<p>7ã€ å¯åŠ¨DataNode</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@localhost hadoop-2.9.1]$ hadoop-daemon.sh start datanode</span><br><span class="line">starting datanode, logging to /home/hadoop/hadoop-2.9.1/logs/hadoop-hadoop-datanode-localhost.localdomain.out</span><br></pre></td></tr></table></figure>
<p>8ã€ å¯åŠ¨SecondaryNameNode</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@localhost hadoop-2.9.1]$ hadoop-daemon.sh start secondarynamenode</span><br><span class="line">starting secondarynamenode, logging to /home/hadoop/hadoop-2.9.1/logs/hadoop-hadoop-secondarynamenode-localhost.localdomain.out</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[hadoop@localhost hadoop-2.9.1]$ jps</span><br><span class="line">7489 NameNode</span><br><span class="line">8167 SecondaryNameNode</span><br><span class="line">8699 Jps</span><br><span class="line">8063 DataNode</span><br><span class="line"></span><br><span class="line">  â”œâ”€java,7489 -Dproc_namenode -Xmx1000m -Djava.library.path=/home/hadoop/hadoop-2.9.1/lib -Djava.net.preferIPv4Stack=<span class="literal">true</span> -Dhadoop.log.dir=/home/hadoop/hadoop-2.9.1/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/home/hadoop/hadoop-2.9.1 -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=<span class="literal">true</span> -Djava.net.preferIPv4Stack=<span class="literal">true</span> -Djava.net.preferIPv4Stack=<span class="literal">true</span> -Dhadoop.log.dir=/home/hadoop/hadoop-2.9.1/logs -Dhadoop.log.file=hadoop-hadoop-namenode-localhost.localdomain.log -Dhadoop.home.dir=/home/hadoop/hadoop-2.9.1 -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=<span class="literal">true</span> -Dhadoop.security.logger=INFO,RFAS -Dhdfs.audit.logger=INFO,NullAppender -Dhadoop.security.logger=INFO,RFAS -Dhdfs.audit.logger=INFO,NullAppender -Dhadoop.security.logger=INFO,RFAS -Dhdfs.audit.logger=INFO,NullAppender -Dhadoop.security.logger=INFO,RFAS org.apache.hadoop.hdfs.server.namenode.NameNode</span><br><span class="line">  </span><br><span class="line">  â”œâ”€java,8063 -Dproc_datanode -Xmx1000m -Djava.library.path=/home/hadoop/hadoop-2.9.1/lib -Djava.net.preferIPv4Stack=<span class="literal">true</span> -Dhadoop.log.dir=/home/hadoop/hadoop-2.9.1/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/home/hadoop/hadoop-2.9.1 -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=<span class="literal">true</span> -Djava.net.preferIPv4Stack=<span class="literal">true</span> -Djava.net.preferIPv4Stack=<span class="literal">true</span> -Dhadoop.log.dir=/home/hadoop/hadoop-2.9.1/logs -Dhadoop.log.file=hadoop-hadoop-datanode-localhost.localdomain.log -Dhadoop.home.dir=/home/hadoop/hadoop-2.9.1 -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=<span class="literal">true</span> -server -Dhadoop.security.logger=ERROR,RFAS -Dhadoop.security.logger=ERROR,RFAS -Dhadoop.security.logger=ERROR,RFAS -Dhadoop.security.logger=INFO,RFAS org.apache.hadoop.hdfs.server.datanode.DataNode</span><br><span class="line"></span><br><span class="line">  â”œâ”€java,8167 -Dproc_secondarynamenode -Xmx1000m -Djava.library.path=/home/hadoop/hadoop-2.9.1/lib -Djava.net.preferIPv4Stack=<span class="literal">true</span> -Dhadoop.log.dir=/home/hadoop/hadoop-2.9.1/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/home/hadoop/hadoop-2.9.1 -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=<span class="literal">true</span> -Djava.net.preferIPv4Stack=<span class="literal">true</span> -Djava.net.preferIPv4Stack=<span class="literal">true</span> -Dhadoop.log.dir=/home/hadoop/hadoop-2.9.1/logs -Dhadoop.log.file=hadoop-hadoop-secondarynamenode-localhost.localdomain.log -Dhadoop.home.dir=/home/hadoop/hadoop-2.9.1 -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=<span class="literal">true</span> -Dhadoop.security.logger=INFO,RFAS -Dhdfs.audit.logger=INFO,NullAppender -Dhadoop.security.logger=INFO,RFAS -Dhdfs.audit.logger=INFO,NullAppender -Dhadoop.security.logger=INFO,RFAS -Dhdfs.audit.logger=INFO,NullAppender -Dhadoop.security.logger=INFO,RFAS org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode</span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"></span><br></pre></td></tr></table></figure>



<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">Usage: hadoop fs [generic options]</span><br><span class="line">	[-appendToFile &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">	[-<span class="built_in">cat</span> [-ignoreCrc] &lt;src&gt; ...]</span><br><span class="line">	[-checksum &lt;src&gt; ...]</span><br><span class="line">	[-<span class="built_in">chgrp</span> [-R] GROUP PATH...]</span><br><span class="line">	[-<span class="built_in">chmod</span> [-R] &lt;MODE[,MODE]... | OCTALMODE&gt; PATH...]</span><br><span class="line">	[-<span class="built_in">chown</span> [-R] [OWNER][:[GROUP]] PATH...]</span><br><span class="line">	[-copyFromLocal [-f] [-p] [-l] [-d] &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">	[-copyToLocal [-f] [-p] [-ignoreCrc] [-crc] &lt;src&gt; ... &lt;localdst&gt;]</span><br><span class="line">	[-count [-q] [-h] [-v] [-t [&lt;storage <span class="built_in">type</span>&gt;]] [-u] [-x] &lt;path&gt; ...]</span><br><span class="line">	[-<span class="built_in">cp</span> [-f] [-p | -p[topax]] [-d] &lt;src&gt; ... &lt;dst&gt;]</span><br><span class="line">	[-createSnapshot &lt;snapshotDir&gt; [&lt;snapshotName&gt;]]</span><br><span class="line">	[-deleteSnapshot &lt;snapshotDir&gt; &lt;snapshotName&gt;]</span><br><span class="line">	[-<span class="built_in">df</span> [-h] [&lt;path&gt; ...]]</span><br><span class="line">	[-<span class="built_in">du</span> [-s] [-h] [-x] &lt;path&gt; ...]</span><br><span class="line">	[-expunge]</span><br><span class="line">	[-find &lt;path&gt; ... &lt;expression&gt; ...]</span><br><span class="line">	[-get [-f] [-p] [-ignoreCrc] [-crc] &lt;src&gt; ... &lt;localdst&gt;]</span><br><span class="line">	[-getfacl [-R] &lt;path&gt;]</span><br><span class="line">	[-getfattr [-R] &#123;-n name | -d&#125; [-e en] &lt;path&gt;]</span><br><span class="line">	[-getmerge [-<span class="built_in">nl</span>] [-skip-empty-file] &lt;src&gt; &lt;localdst&gt;]</span><br><span class="line">	[-<span class="built_in">help</span> [cmd ...]]</span><br><span class="line">	[-<span class="built_in">ls</span> [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [&lt;path&gt; ...]]</span><br><span class="line">	[-<span class="built_in">mkdir</span> [-p] &lt;path&gt; ...]</span><br><span class="line">	[-moveFromLocal &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">	[-moveToLocal &lt;src&gt; &lt;localdst&gt;]</span><br><span class="line">	[-<span class="built_in">mv</span> &lt;src&gt; ... &lt;dst&gt;]</span><br><span class="line">	[-put [-f] [-p] [-l] [-d] &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">	[-renameSnapshot &lt;snapshotDir&gt; &lt;oldName&gt; &lt;newName&gt;]</span><br><span class="line">	[-<span class="built_in">rm</span> [-f] [-r|-R] [-skipTrash] [-safely] &lt;src&gt; ...]</span><br><span class="line">	[-<span class="built_in">rmdir</span> [--ignore-fail-on-non-empty] &lt;<span class="built_in">dir</span>&gt; ...]</span><br><span class="line">	[-setfacl [-R] [&#123;-b|-k&#125; &#123;-m|-x &lt;acl_spec&gt;&#125; &lt;path&gt;]|[--<span class="built_in">set</span> &lt;acl_spec&gt; &lt;path&gt;]]</span><br><span class="line">	[-setfattr &#123;-n name [-v value] | -x name&#125; &lt;path&gt;]</span><br><span class="line">	[-setrep [-R] [-w] &lt;rep&gt; &lt;path&gt; ...]</span><br><span class="line">	[-<span class="built_in">stat</span> [format] &lt;path&gt; ...]</span><br><span class="line">	[-<span class="built_in">tail</span> [-f] &lt;file&gt;]</span><br><span class="line">	[-<span class="built_in">test</span> -[defsz] &lt;path&gt;]</span><br><span class="line">	[-text [-ignoreCrc] &lt;src&gt; ...]</span><br><span class="line">	[-touchz &lt;path&gt; ...]</span><br><span class="line">	[-<span class="built_in">truncate</span> [-w] &lt;length&gt; &lt;path&gt; ...]</span><br><span class="line">	[-usage [cmd ...]]</span><br><span class="line"></span><br><span class="line">Generic options supported are:</span><br><span class="line">-conf &lt;configuration file&gt;        specify an application configuration file</span><br><span class="line">-D &lt;property=value&gt;               define a value <span class="keyword">for</span> a given property</span><br><span class="line">-fs &lt;file:///|hdfs://namenode:port&gt; specify default filesystem URL to use, overrides <span class="string">&#x27;fs.defaultFS&#x27;</span> property from configurations.</span><br><span class="line">-jt &lt;<span class="built_in">local</span>|resourcemanager:port&gt;  specify a ResourceManager</span><br><span class="line">-files &lt;file1,...&gt;                specify a comma-separated list of files to be copied to the map reduce cluster</span><br><span class="line">-libjars &lt;jar1,...&gt;               specify a comma-separated list of jar files to be included <span class="keyword">in</span> the classpath</span><br><span class="line">-archives &lt;archive1,...&gt;          specify a comma-separated list of archives to be unarchived on the compute machines</span><br><span class="line"></span><br><span class="line">The general <span class="built_in">command</span> line syntax is:</span><br><span class="line"><span class="built_in">command</span> [genericOptions] [commandOptions]</span><br><span class="line"></span><br><span class="line">Usage: hadoop fs [generic options] -<span class="built_in">ls</span> [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [&lt;path&gt; ...]</span><br><span class="line">[hadoop@localhost ~]$ </span><br></pre></td></tr></table></figure>

<p>9ã€ HDFSä¸Šæµ‹è¯•åˆ›å»ºç›®å½•ã€ä¸Šä¼ ã€ä¸‹è½½æ–‡ä»¶</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åˆ›å»ºä¸€ä¸ªç›®å½•ï¼Œ</span></span><br><span class="line">[hadoop@localhost ~]$ hdfs dfs -<span class="built_in">mkdir</span> /demo1</span><br><span class="line"></span><br><span class="line"><span class="comment"># ä¸Šä¼ æœ¬åœ°æ–‡ä»¶åˆ°HDFSä¸Š</span></span><br><span class="line">[hadoop@localhost ~]$ hdfs dfs -put hadoop-2.9.1.tar.gz  /demo1</span><br><span class="line"></span><br><span class="line"><span class="comment">#è¯»å–HDFSä¸Šçš„æ–‡ä»¶å†…å®¹</span></span><br><span class="line">[hadoop@localhost ~]$ hdfs dfs -put hadoop-2.9.1/bin/hadoop /demo1</span><br><span class="line">[hadoop@localhost ~]$ hdfs dfs -<span class="built_in">ls</span> -R /</span><br><span class="line">drwxr-xr-x   - hadoop supergroup          0 2018-10-22 18:15 /demo1</span><br><span class="line">-rw-r--r--   1 hadoop supergroup       6656 2018-10-22 18:15 /demo1/hadoop</span><br><span class="line">-rw-r--r--   1 hadoop supergroup  361355307 2018-10-22 18:06 /demo1/hadoop-2.9.1.tar.gz</span><br><span class="line"><span class="comment">#è¯»å–HDFSä¸Šçš„æ–‡ä»¶å†…å®¹</span></span><br><span class="line">[hadoop@localhost ~]$ hdfs dfs -<span class="built_in">cat</span> /demo1/hadoop</span><br><span class="line"></span><br><span class="line"><span class="comment"># ä»HDFSä¸Šä¸‹è½½æ–‡ä»¶åˆ°æœ¬åœ°</span></span><br><span class="line">[hadoop@localhost ~]$ hdfs dfs -get /demo1/hadoop</span><br></pre></td></tr></table></figure>

<p>é…ç½®ã€å¯åŠ¨YARN</p>
<p>1ã€ é…ç½®mapred-site.xml</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># é»˜è®¤æ²¡æœ‰mapred-site.xmlæ–‡ä»¶ï¼Œä½†æ˜¯æœ‰ä¸ªmapred-site.xml.templateé…ç½®æ¨¡æ¿æ–‡ä»¶ã€‚å¤åˆ¶æ¨¡æ¿ç”Ÿæˆmapred-site.xmlã€‚</span></span><br><span class="line">[hadoop@localhost hadoop]$ <span class="built_in">cp</span> mapred-site.xml.template  mapred-site.xml</span><br><span class="line">[hadoop@localhost hadoop]$ vi mapred-site.xml</span><br><span class="line">[hadoop@localhost hadoop]$ <span class="built_in">cat</span> mapred-site.xml</span><br><span class="line">&lt;?xml version=<span class="string">&quot;1.0&quot;</span>?&gt;</span><br><span class="line">&lt;?xml-stylesheet <span class="built_in">type</span>=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span><br><span class="line">&lt;!--</span><br><span class="line">  Licensed under the Apache License, Version 2.0 (the <span class="string">&quot;License&quot;</span>);</span><br><span class="line">  you may not use this file except <span class="keyword">in</span> compliance with the License.</span><br><span class="line">  You may obtain a copy of the License at</span><br><span class="line"></span><br><span class="line">    http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="line"></span><br><span class="line">  Unless required by applicable law or agreed to <span class="keyword">in</span> writing, software</span><br><span class="line">  distributed under the License is distributed on an <span class="string">&quot;AS IS&quot;</span> BASIS,</span><br><span class="line">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="line">  See the License <span class="keyword">for</span> the specific language governing permissions and</span><br><span class="line">  limitations under the License. See accompanying LICENSE file.</span><br><span class="line">--&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- Put site-specific property overrides <span class="keyword">in</span> this file. --&gt;</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;æŒ‡å®šmapreduceè¿è¡Œåœ¨yarnæ¡†æ¶ä¸Šã€‚</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line">[hadoop@localhost hadoop]$</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>2ã€ é…ç½®yarn-site.xml</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">æ·»åŠ é…ç½®å¦‚ä¸‹ï¼š</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;your ip&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br></pre></td></tr></table></figure>

<p>3ã€ å¯åŠ¨Resourcemanager</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@localhost hadoop]$ yarn-daemon.sh start resourcemanager</span><br><span class="line">starting resourcemanager, logging to /home/hadoop/hadoop-2.9.1/logs/yarn-hadoop-resourcemanager-localhost.localdomain.out</span><br></pre></td></tr></table></figure>

<p>4ã€ å¯åŠ¨nodemanager</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[hadoop@localhost hadoop]$ yarn-daemon.sh start nodemanager</span><br><span class="line">starting nodemanager, logging to /home/hadoop/hadoop-2.9.1/logs/yarn-hadoop-nodemanager-localhost.localdomain.out</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>5ã€ æŸ¥çœ‹æ˜¯å¦å¯åŠ¨æˆåŠŸ</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@localhost hadoop]$ jps</span><br><span class="line">7255 ResourceManager</span><br><span class="line">6105 DataNode</span><br><span class="line">5834 NameNode</span><br><span class="line">7532 NodeManager</span><br><span class="line">6412 SecondaryNameNode</span><br><span class="line">7678 Jps  <span class="comment"># å¯ä»¥çœ‹åˆ°ResourceManagerã€NodeManagerå·²ç»å¯åŠ¨æˆåŠŸäº†ã€‚</span></span><br></pre></td></tr></table></figure>
<p>6ã€ YARNçš„Webé¡µé¢</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">YARNçš„Webå®¢æˆ·ç«¯ç«¯å£å·æ˜¯8088ï¼Œ</span><br><span class="line"></span><br><span class="line">http://10.0.63.48:8088/cluster</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>




<h1 id="å®Œå…¨åˆ†å¸ƒå¼å®‰è£…"><a href="#å®Œå…¨åˆ†å¸ƒå¼å®‰è£…" class="headerlink" title="å®Œå…¨åˆ†å¸ƒå¼å®‰è£…"></a>å®Œå…¨åˆ†å¸ƒå¼å®‰è£…</h1><h1 id="é«˜å¯ç”¨æ¨¡å¼å®‰è£…"><a href="#é«˜å¯ç”¨æ¨¡å¼å®‰è£…" class="headerlink" title="é«˜å¯ç”¨æ¨¡å¼å®‰è£…"></a>é«˜å¯ç”¨æ¨¡å¼å®‰è£…</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hdfs://sxt&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;/home/hadoop/hadoop-2.9.1/data&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;namenode1:2181,namenode2:2181,namenode3:2181&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;!-- http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.nameservices&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;sxt&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.ha.namenodes.sxt&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;namenode1,namenode2&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- é…ç½®rpcé€šä¿¡æ¥å£çš„ --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.rpc-address.sxt.namenode1&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;namenode1:8020&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.rpc-address.sxt.namenode2&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;namenode2:8020&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.http-address.sxt.namenode1&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;namenode1:50070&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.http-address.sxt.namenode2&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;namenode2:50070&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;qjournal://namenode1:8485;namenode2:8485;namenode3:8485/sxt&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.client.failover.proxy.provider.sxt&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;/home/hadoop/hadoop-2.9.1/journal&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">     &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;<span class="literal">true</span>&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;sshfence&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;/home/hadoop/.ssh/id_rsa&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br></pre></td></tr></table></figure>


</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">æ–‡ç« ä½œè€…: </span><span class="post-copyright-info"><a href="https://magesfc.github.io">mage</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">æ–‡ç« é“¾æ¥: </span><span class="post-copyright-info"><a href="https://magesfc.github.io/mage/de5f9aaadaa19a9005fc5140c7198eed7fd8b7e5/">https://magesfc.github.io/mage/de5f9aaadaa19a9005fc5140c7198eed7fd8b7e5/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">ç‰ˆæƒå£°æ˜: </span><span class="post-copyright-info">æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ«å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨ <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥è‡ª <a href="https://magesfc.github.io" target="_blank">é©¬å“¥ç§æˆ¿èœ</a>ï¼</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/hadoop/">hadoop</a></div><div class="post_share"><div class="social-share" data-image="https://t.mwm.moe/fj/" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> æ‰“èµ</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/null" target="_blank"><img class="post-qr-code-img" src= "/img/loading.gif" data-lazy-src="/null" alt="å¾®ä¿¡"/></a><div class="post-qr-code-desc">å¾®ä¿¡</div></li><li class="reward-item"><a href="/null" target="_blank"><img class="post-qr-code-img" src= "/img/loading.gif" data-lazy-src="/null" alt="æ”¯ä»˜å¯¶"/></a><div class="post-qr-code-desc">æ”¯ä»˜å¯¶</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/mage/5fa01cc433ce609529dd958233f788745c01668f/"><img class="prev-cover" src= "/img/loading.gif" data-lazy-src="https://t.mwm.moe/fj/" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">ä¸Šä¸€ç¯‡</div><div class="prev_info">Codemonkeyä¹‹ç¼–ç å†’é™©ç‰¹æŠ€æ¨¡å¼1-165å…³å¡</div></div></a></div><div class="next-post pull-right"><a href="/mage/9c016a864ddabbb8f6fb2055b17dd05ebec955f6/"><img class="next-cover" src= "/img/loading.gif" data-lazy-src="https://t.mwm.moe/fj/" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">ä¸‹ä¸€ç¯‡</div><div class="next_info">Hibernateå­¦ä¹ ä¹‹äºŒçº§ç¼“å­˜</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "/img/loading.gif" data-lazy-src="/img/avatar.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">mage</div><div class="author-info__description"> è¿™é‡Œæ˜¯ é©¬å“¥ çš„ä¸ªäººåšå®¢ </div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">æ–‡ç« </div><div class="length-num">213</div></a><a href="/tags/"><div class="headline">æ ‡ç­¾</div><div class="length-num">228</div></a><a href="/categories/"><div class="headline">åˆ†ç±»</div><div class="length-num">40</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/mamh2021"><i class="fab fa-github"></i><span>GitHub</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/mamh2021" target="_blank" title="Github"><i class="fab fa-github"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>å…¬å‘Š</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>ç›®å½•</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%BC%95%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text">å¼•è¨€</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Namenode-%E5%92%8C-Datanode"><span class="toc-number">2.</span> <span class="toc-text">Namenode å’Œ Datanode</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%89%E8%A3%85hadoop%E5%87%86%E5%A4%87"><span class="toc-number">3.</span> <span class="toc-text">å®‰è£…hadoopå‡†å¤‡</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%9C%AC%E5%9C%B0%E6%A8%A1%E5%BC%8F%E9%83%A8%E7%BD%B2"><span class="toc-number">4.</span> <span class="toc-text">æœ¬åœ°æ¨¡å¼éƒ¨ç½²</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Hadoop%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E6%A8%A1%E5%BC%8F%E5%AE%89%E8%A3%85"><span class="toc-number">5.</span> <span class="toc-text">Hadoopä¼ªåˆ†å¸ƒå¼æ¨¡å¼å®‰è£…</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%89%E8%A3%85"><span class="toc-number">6.</span> <span class="toc-text">å®Œå…¨åˆ†å¸ƒå¼å®‰è£…</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%AB%98%E5%8F%AF%E7%94%A8%E6%A8%A1%E5%BC%8F%E5%AE%89%E8%A3%85"><span class="toc-number">7.</span> <span class="toc-text">é«˜å¯ç”¨æ¨¡å¼å®‰è£…</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>æœ€æ–°æ–‡ç« </span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/mage/145f51d0e22fead4fc7b2a02f114a5766064789d/" title="Dockeræºç å­¦ä¹ ä¹‹å®¹å™¨çš„éšæœºçš„åå­—æ€ä¹ˆæ¥çš„y"><img src= "/img/loading.gif" data-lazy-src="https://t.mwm.moe/fj/" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Dockeræºç å­¦ä¹ ä¹‹å®¹å™¨çš„éšæœºçš„åå­—æ€ä¹ˆæ¥çš„y"/></a><div class="content"><a class="title" href="/mage/145f51d0e22fead4fc7b2a02f114a5766064789d/" title="Dockeræºç å­¦ä¹ ä¹‹å®¹å™¨çš„éšæœºçš„åå­—æ€ä¹ˆæ¥çš„y">Dockeræºç å­¦ä¹ ä¹‹å®¹å™¨çš„éšæœºçš„åå­—æ€ä¹ˆæ¥çš„y</a><time datetime="2023-09-26T14:32:47.000Z" title="æ›´æ–°äº 2023-09-26 22:32:47">2023-09-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/mage/eee219318da0b6a390e2e2d9c27459533c760b0c/" title="Dockeræºç å­¦ä¹ ä¹‹docker-runå‘½ä»¤"><img src= "/img/loading.gif" data-lazy-src="https://t.mwm.moe/fj/" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Dockeræºç å­¦ä¹ ä¹‹docker-runå‘½ä»¤"/></a><div class="content"><a class="title" href="/mage/eee219318da0b6a390e2e2d9c27459533c760b0c/" title="Dockeræºç å­¦ä¹ ä¹‹docker-runå‘½ä»¤">Dockeræºç å­¦ä¹ ä¹‹docker-runå‘½ä»¤</a><time datetime="2023-09-26T14:05:28.000Z" title="æ›´æ–°äº 2023-09-26 22:05:28">2023-09-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/mage/d8e5ec1afedee09998d034f01da122815a3d1292/" title="Dockeræºç å­¦ä¹ ä¹‹dockerå‘½ä»¤è¡Œå‚æ•°è§£ææµç¨‹"><img src= "/img/loading.gif" data-lazy-src="https://t.mwm.moe/fj/" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Dockeræºç å­¦ä¹ ä¹‹dockerå‘½ä»¤è¡Œå‚æ•°è§£ææµç¨‹"/></a><div class="content"><a class="title" href="/mage/d8e5ec1afedee09998d034f01da122815a3d1292/" title="Dockeræºç å­¦ä¹ ä¹‹dockerå‘½ä»¤è¡Œå‚æ•°è§£ææµç¨‹">Dockeræºç å­¦ä¹ ä¹‹dockerå‘½ä»¤è¡Œå‚æ•°è§£ææµç¨‹</a><time datetime="2023-09-24T08:07:37.000Z" title="æ›´æ–°äº 2023-09-24 16:07:37">2023-09-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/mage/f6c177061422199002a80ffbf5445a81e9751b46/" title="Dockerå­¦ä¹ ä¹‹å¦‚ä½•æºç ç¼–è¯‘docker"><img src= "/img/loading.gif" data-lazy-src="https://t.mwm.moe/fj/" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Dockerå­¦ä¹ ä¹‹å¦‚ä½•æºç ç¼–è¯‘docker"/></a><div class="content"><a class="title" href="/mage/f6c177061422199002a80ffbf5445a81e9751b46/" title="Dockerå­¦ä¹ ä¹‹å¦‚ä½•æºç ç¼–è¯‘docker">Dockerå­¦ä¹ ä¹‹å¦‚ä½•æºç ç¼–è¯‘docker</a><time datetime="2023-09-24T05:50:00.000Z" title="æ›´æ–°äº 2023-09-24 13:50:00">2023-09-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/mage/7b272222e11710ea56798b3ea16707c83ea0138f/" title="Androidä¸‹çš„é…ç½®ç®¡ç†ä¹‹é“ç¼–è¯‘é«˜é€šwlançš„æ„å»º"><img src= "/img/loading.gif" data-lazy-src="https://t.mwm.moe/fj/" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Androidä¸‹çš„é…ç½®ç®¡ç†ä¹‹é“ç¼–è¯‘é«˜é€šwlançš„æ„å»º"/></a><div class="content"><a class="title" href="/mage/7b272222e11710ea56798b3ea16707c83ea0138f/" title="Androidä¸‹çš„é…ç½®ç®¡ç†ä¹‹é“ç¼–è¯‘é«˜é€šwlançš„æ„å»º">Androidä¸‹çš„é…ç½®ç®¡ç†ä¹‹é“ç¼–è¯‘é«˜é€šwlançš„æ„å»º</a><time datetime="2023-09-22T16:13:06.000Z" title="æ›´æ–°äº 2023-09-23 00:13:06">2023-09-23</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://t.mwm.moe/fj/')"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2023 By mage</div><div class="framework-info"><span>æ¡†æ¶ </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>ä¸»é¢˜ </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="é˜…è¯»æ¨¡å¼"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="æµ…è‰²å’Œæ·±è‰²æ¨¡å¼è½¬æ¢"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="å•æ å’ŒåŒæ åˆ‡æ¢"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="è®¾ç½®"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="ç›®å½•"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="å›åˆ°é¡¶éƒ¨"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><div class="js-pjax"><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script></div><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="true" data-click="true"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>